{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\real-estate-demo\\src\\agents\\__init__.py:13: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\",\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st \n",
    "from src.agents import RealEstateAgent\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "\n",
    "\n",
    "# Initialize the RealEstateAgent\n",
    "agent_builder = RealEstateAgent()\n",
    "agent = agent_builder.build_agent()\n",
    "\n",
    "# Initialize speech recognition and synthesis\n",
    "recognizer = sr.Recognizer()\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "\n",
    "def listen():\n",
    "    #stt\n",
    "    try:\n",
    "        with sr.Microphone() as source:\n",
    "            print(\"Listening...\")\n",
    "            audio = recognizer.listen(source)\n",
    "            return recognizer.recognize_google(audio)\n",
    "    except sr.UnknownValueError:\n",
    "        return \"Sorry, I didn't catch that.\"\n",
    "    except sr.RequestError as e:\n",
    "        return f\"Speech recognition service error: {e}\"\n",
    "\n",
    "def speak_text(text):\n",
    "    #tts\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# if st.button(\"Start\"):\n",
    "# # Main interaction loop\n",
    "#     while True:\n",
    "#         query = listen()\n",
    "#         print(\"Input:\", query)\n",
    "        \n",
    "#         if query.lower() == \"exit\":  # Stop condition\n",
    "#             print(\"Exiting the loop.\")\n",
    "#             break\n",
    "\n",
    "#         # Process the input query\n",
    "#         output = agent.invoke({\"input\": query})\n",
    "\n",
    "#         # Get the assistant's response\n",
    "#         response = output['output']\n",
    "#         print(\"Assistant:\", response)\n",
    "#         speak_text(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speech_recognition import Microphone, Recognizer, UnknownValueError\n",
    "\n",
    "def audio_callback(recognizer, audio):\n",
    "    try:\n",
    "        query = recognizer.recognize_whisper(audio, model=\"base\", language=\"english\")\n",
    "        output = agent.invoke({\"input\": query})\n",
    "        response = output['output']\n",
    "        print(\"Assistant:\", response)\n",
    "        speak_text(response)\n",
    "\n",
    "        \n",
    "    except UnknownValueError:\n",
    "        print(\"There was an error processing the audio.\")\n",
    "\n",
    "\n",
    "recognizer = Recognizer()\n",
    "microphone = Microphone()\n",
    "\n",
    "\n",
    "\n",
    "with microphone as source:\n",
    "    recognizer.adjust_for_ambient_noise(source)\n",
    "\n",
    "stop_listening = recognizer.listen_in_background(microphone, audio_callback)\n",
    "\n",
    "\n",
    "stop_listening(wait_for_stop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
